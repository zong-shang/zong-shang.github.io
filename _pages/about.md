---
permalink: /
title: "About Me"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

I am a 3rd year Ph.D. student in the Department of Statistics at CREST-ENSAE, Institut Polytechnique de Paris, supervised by <a href="https://guillaume-lecue.faculty.essec.edu/">Guillaume Lecu\'e</a> and <a href="https://lerasle.perso.math.cnrs.fr/">Matthieu Lerasle</a>. On this homepage, you can find some of my reflections on mathematical statistics and statistical learning theory.  Starting from the fall of 2026, I will join the School of Mathematics at the Georgia Institute of Technology as a Visiting Assistant Professor. My mentor will be Vladimir Koltchinskii.

## Research Interests

I am interested in Mathematical Statistics and Statistical Learning Theory. My research focuses on refining the fundamental methodologies of the field, specifically the uniform convergence argument.

In collaboration with my PhD advisor, Guillaume Lecu\'e, I developed the Feature Space Decomposition (FSD) method. FSD provides theoretical statisticians with a novel analytical tool and a transformative framework for understanding high-dimensional structures. Motivated by the phenomenon of benign overfitting, this methodology bridges the gap between mathematical statistics and the Geometric Aspects of Functional Analysis (GAFA). My work utilizes classical GAFA results while developing new generalizations inspired by the rigorous demands of modern statistical problems.

Below are some of the research keywords of my research:

* **Statistical Learning Theory**: Uniform convergence argument, localization, multiplier & quadratic processes, fixed-point analysis, (local) Bernstein's condition.
* **Geometric Aspects of Functional Analysis**: Dvoretzky-Milman theorem, generic chaining, small-ball method, empirical process theory, Gaussian mean width, Rademacher complexity, restricted strong convexity (RSC), restricted isomorphic property (RIP).
* **Learning procedues and Statistical Models**: Empirical Risk Minimization (ERM), Regularized Empirical Risk Minimization (RERM), M-estimators, ridge regression, Gradient Descent, Gradient Flow, Principle Components Regression (PCR), spectral methods, mean-field shallow neural network, mean-field Langevin dynamics, reproducing kernel Hilbert spaces (RKHS), reproducing kernel Banach spaces (RKBS), latent factor model, single- and multi-index regression.
* **Phenomena**: Benign overfitting, feature learning, saturation effect.

## Education

* **PhD in Applied Mathematics**: CREST-ENSAE, Insitut Polytechnique de Paris, Palaiseau, Frace (2023 – **Expected April 2026**).
  * **Thesis Title**: Feature Space Decomposition.
  * **Supervisors**: Guillaume Lecu\'e, and Matthieu Lerasle.
  * **Reviewers**: Vladimir Koltchinskii, and Sara Van de Geer.
  * **Jury**: Alexandre Tsybakov, Claire Boyer, Marta Strzelecka, and Taiji Suzuki.
* **Master in Applied Mathematics and Statistics**: Data Science, Institut Polytechnique de Paris, Palaiseau, France (2021 - 2023).
* **B.S. in Computer Science**, College of Computer Science and Technology, Jilin University, Changchun, China (2017 – 2021).

## Research Style

My favorite words in mathematics come from Grothendieck’s Récoltes et Semailles (1985, pp. 552-3-1):

“I can illustrate the second approach with the same image of a nut to be opened.

The first analogy that came to my mind is of immersing the nut in some softening liquid, and why not simply water? From time to time you rub so the liquid penetrates better,and otherwise you let time pass. The shell becomes more flexible through weeks and months – when the time is ripe, hand pressure is enough, the shell opens like a perfectly ripened avocado!

A different image came to me a few weeks ago.

The unknown thing to be known appeared to me as some stretch of earth or hard marl, resisting penetration… the sea advances insensibly in silence, nothing seems to happen, nothing moves, the water is so far off you hardly hear it.. yet it finally surrounds the resistant substance.”

Even though I do not speak French, this image of the rising sea has always resonated with me — gentle, patient, and inexorable, much like the way I hope mathematics reveals its truths.

This 'rising sea' philosophy guides my own approach to research. I am a firm believer that in mathematics, the 'hard work' should be done by the definitions and the framework themselves. When the conceptual architecture is built with enough care and insight, the theorems should not be forced; they should emerge as natural, almost quiet, consequences of the structures we have defined. For me, a proof is most beautiful when it feels less like a conquest and more like a discovery made inevitable by the right perspective.

